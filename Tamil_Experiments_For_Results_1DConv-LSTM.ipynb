{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd\n",
    "import re\n",
    "import gc\n",
    "import os\n",
    "import fileinput\n",
    "import string\n",
    "import tensorflow as tf\n",
    "import zipfile\n",
    "import datetime\n",
    "import sys\n",
    "from tqdm  import tqdm\n",
    "tqdm.pandas()\n",
    "from nltk.tokenize import wordpunct_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem.snowball import SnowballStemmer\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import f1_score, roc_auc_score\n",
    "\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Flatten, LSTM, Conv1D, MaxPooling1D, Dropout, Activation\n",
    "from keras.layers.embeddings import Embedding\n",
    "from sklearn.metrics import classification_report\n",
    "from keras.utils import np_utils\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "# load and evaluate a saved model\n",
    "from numpy import loadtxt\n",
    "from keras.models import load_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "os.environ[\"CUDA_DEVICE_ORDER\"]=\"PCI_BUS_ID\"\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"2\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def detect(tokens):\n",
    "    return [t for t in tokens if t in valid_forms]\n",
    "    \n",
    "def replace_blank(tokens):\n",
    "    return [blank if t in valid_forms else t for t in tokens]\n",
    "\n",
    "def create_windows(tokens, window_size=3):\n",
    "    X = []\n",
    "    for i, word in enumerate(tokens):\n",
    "        if word == blank:\n",
    "            window = tokens[i-window_size:i] + tokens[i+1:i+window_size+1]\n",
    "            window = ' '.join(window)\n",
    "            X.append(window)    \n",
    "    return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(15744, 2)\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv('Tamil_first_ready_for_sentiment.csv',sep='\\t',names=['category','text'])\n",
    "print(df.shape)\n",
    "\n",
    "df['text'] = df.text.str.lower().str.replace(r'['+string.digits+string.punctuation+']', ' ')\n",
    "df['text'] = df['text'].apply(lambda x: x.split())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: 'Negative ',\n",
       " 1: 'Positive ',\n",
       " 2: 'Mixed feelings ',\n",
       " 3: 'not-Tamil ',\n",
       " 4: 'unknown state '}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y=df['category']\n",
    "#y = pd.get_dummies(df['category']).values\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(df['text'].tolist(), y, random_state=5, test_size=0.2)\n",
    "from sklearn.utils import class_weight\n",
    "class_weights = class_weight.compute_class_weight('balanced',\n",
    "                                                 np.unique(y_train),\n",
    "                                                 y_train)\n",
    "y_train=pd.get_dummies(y_train).values\n",
    "y_test=pd.get_dummies(y_test).values\n",
    "diz_label = {}\n",
    "for i,label in enumerate(df.category.factorize()[1]):\n",
    "    diz_label[i] = label\n",
    "    \n",
    "diz_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocabulary_size = 20000\n",
    "tokenizer = Tokenizer(num_words= vocabulary_size)\n",
    "tokenizer.fit_on_texts(X_train)\n",
    "sequences = tokenizer.texts_to_sequences(X_train)\n",
    "X_train = pad_sequences(sequences, maxlen=50)\n",
    "sequences = tokenizer.texts_to_sequences(X_test)\n",
    "X_test = pad_sequences(sequences, maxlen=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Embedding(20000, 100, input_length=50))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Conv1D(64, 5, activation='relu'))\n",
    "model.add(MaxPooling1D(pool_size=2))\n",
    "model.add(LSTM(100))\n",
    "model.add(Dense(5, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0131 16:28:12.253907 140269875492608 deprecation.py:323] From /home/bharaj/anaconda3/lib/python3.6/site-packages/tensorflow/python/ops/math_grad.py:1250: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 11335 samples, validate on 1260 samples\n",
      "Epoch 1/10\n",
      "11335/11335 [==============================] - 7s 595us/step - loss: 1.3379 - acc: 0.6211 - val_loss: 1.1087 - val_acc: 0.6794\n",
      "Epoch 2/10\n",
      "11335/11335 [==============================] - 1s 69us/step - loss: 1.0603 - acc: 0.6730 - val_loss: 1.0260 - val_acc: 0.6794\n",
      "Epoch 3/10\n",
      "11335/11335 [==============================] - 1s 69us/step - loss: 1.0234 - acc: 0.6730 - val_loss: 1.0076 - val_acc: 0.6794\n",
      "Epoch 4/10\n",
      "11335/11335 [==============================] - 1s 70us/step - loss: 0.9946 - acc: 0.6730 - val_loss: 0.9862 - val_acc: 0.6794\n",
      "Epoch 5/10\n",
      "11335/11335 [==============================] - 1s 67us/step - loss: 0.9387 - acc: 0.6730 - val_loss: 0.9513 - val_acc: 0.6794\n",
      "Epoch 6/10\n",
      "11335/11335 [==============================] - 1s 72us/step - loss: 0.8477 - acc: 0.6783 - val_loss: 0.9426 - val_acc: 0.6802\n",
      "Epoch 7/10\n",
      "11335/11335 [==============================] - 1s 71us/step - loss: 0.7597 - acc: 0.7274 - val_loss: 0.9807 - val_acc: 0.6786\n",
      "Epoch 8/10\n",
      "11335/11335 [==============================] - 1s 73us/step - loss: 0.6663 - acc: 0.7536 - val_loss: 1.0383 - val_acc: 0.6532\n",
      "Epoch 9/10\n",
      "11335/11335 [==============================] - 1s 70us/step - loss: 0.5848 - acc: 0.7848 - val_loss: 1.1195 - val_acc: 0.6286\n",
      "Epoch 10/10\n",
      "11335/11335 [==============================] - 1s 69us/step - loss: 0.5108 - acc: 0.8211 - val_loss: 1.2203 - val_acc: 0.6563\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f9293b747b8>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train, y_train,\n",
    "                    batch_size=1024,\n",
    "                    epochs=10,\n",
    "                    verbose=1,\n",
    "                    validation_split=0.1,class_weight=class_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3149/3149 [==============================] - 0s 86us/step\n",
      "Test accuracy: 0.6348046994126005\n"
     ]
    }
   ],
   "source": [
    "score = model.evaluate(X_test, y_test,\n",
    "                       batch_size=256, verbose=1)\n",
    "print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "preds = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# {0: 'Negative ',\n",
    "#  1: 'Positive ',\n",
    "#  2: 'Mixed feelings ',\n",
    "#  3: 'not-Tamil ',\n",
    "#  4: 'unknown state '}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.14      0.10      0.12       377\n",
      "           1       0.30      0.11      0.16       424\n",
      "           2       0.71      0.91      0.80      2075\n",
      "           3       0.67      0.28      0.39       100\n",
      "           4       0.00      0.00      0.00       173\n",
      "\n",
      "   micro avg       0.63      0.63      0.63      3149\n",
      "   macro avg       0.36      0.28      0.29      3149\n",
      "weighted avg       0.54      0.63      0.57      3149\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/bharaj/anaconda3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(np.argmax(y_test,axis=1),np.argmax(preds,axis=1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import itertools\n",
    "def plot_confusion_matrix(cm, classes, title='Confusion matrix', cmap=plt.cm.Blues):\n",
    "\n",
    "    cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    plt.title(title, fontsize=25)\n",
    "    #plt.colorbar()\n",
    "    tick_marks = np.arange(len(classes))\n",
    "    plt.xticks(tick_marks, classes, rotation=90, fontsize=15)\n",
    "    plt.yticks(tick_marks, classes, fontsize=15)\n",
    "\n",
    "    fmt = '.2f'\n",
    "    thresh = cm.max() / 2.\n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        plt.text(j, i, format(cm[i, j], fmt),\n",
    "                 horizontalalignment=\"center\",\n",
    "                 color=\"white\" if cm[i, j] > thresh else \"black\", fontsize = 14)\n",
    "\n",
    "    plt.ylabel('True label', fontsize=20)\n",
    "    plt.xlabel('Predicted label', fontsize=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cnf_matrix = confusion_matrix([diz_label[i] for i in np.argmax(y_test, axis=1)], \n",
    "#                               [diz_label[i] for i in np.argmax(preds, axis=1)])\n",
    "\n",
    "# plt.figure(figsize=(7,7))\n",
    "# plot_confusion_matrix(cnf_matrix, classes=list(diz_label.values()), title=\"Confusion matrix DME\")\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
